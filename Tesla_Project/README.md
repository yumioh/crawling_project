# LDA 주제 모델링으로 주제를 추출로 금융 시장 변동성 분석 <br/> (논문기반으로 구현) 

#### 사용언어 : python
#### 사용 Tools : VScode

# 논문 개요 
  - 논문명 : High Quality Topic Extraction from Business News Explains Abnormal Financial Market Volatility
  - 뉴스를 분석하여 주식 시장의 거래 활동과의 연관성을 제시
  - 거래활동과 뉴스 정보를 단순 정규회귀 분석
  - 토픽 모델링 기술을 사용하여 주제별 기능 구현
  - 뉴스가 주가에 미치는 영향을 자동적으로 요약, 예측, 정량화 함
  - 뉴스가 최신 정보이며 관련 금융 정보를 제공한다면 과잉 거래는 없다는 것을 입증
<br>

# 데이터 수집 

## 1. 테슬라 주가
    - 기간 : 2020.01.01 ~ 2023.09.30 (3년 9개월)
    - 수집대상 : 테슬라 주가 (인베스팅 사이트 통한 주가 파일 다운로드)
    - 수집항목 : 날짜, 종가, 시가, 고가, 저가, 거래량, 변동
    - stocks.csv 파일로 저장

## 2. 테슬라 뉴스
    - 기간 : 2020.01.01 ~ 2023.09.30 (3년 9개월)
    - 수집대상 : 네이버 뉴스 기준으로 이데일리, 한국경제, 전자신문 등 뉴스 데이터 수집 (웹 크롤링)
    - 수집항목 : 날짜, 타이틀, 기사본문, 카테고리 (카테고리가 여러개로 분류 될 경우 가장 앞에 있는 카테고리로 추출)
    - teslaNews_YYMM.csv파일로 저장

## 3. 테슬라 트위터
    - 기간 : 2020.01.01 ~ 2023.09.30 (3년 9개월)
    - 수집대상 : 일론 머스크의 twitter 데이터 수집 (selenium 사용)
    - 수집항목 : 아이디, 유저이름, 내용, 날짜 
    - YYYY_twit_data.csv파일로 저장
<br/>

# 데이터 전처리

## 1. 뉴스 기사 데이터 전처리 
    - 날짜 타입 변경, 공백처리, 불용어 처리, 기사 길이가 140 이하 삭제
    - NaN값을 빈 문자열로 대체 
    
| 결측지 제거 후 | dataframe shape | (114308, 3) |
|------|---|---|
| <b>결측지 제거 전 </b> | <b> dataframe shape</b> | <b>(114208, 3)</b> |

## 2. 주식 데이터 전처리 
    - 날짜 타입 변경, 거래량 M을 제외한 숫자로만 표기 처리
    - 날짜와 거래량만 추출
    - 주식 데이터와 열 이름 통일, 기사 데이터 날짜별 기사 수 추출

## 2. 주식 데이터 전처리 
    - 날짜 타입 변경, 거래량 M을 제외한 숫자로만 표기 처리
    - 날짜와 거래량만 추출

## 3. 주식과 기사 데이터 병합
    - 주가 없는 날짜 제거
    - 주식과 관련된 키워드 행 삭제 : 주가 변동 키워드 분석이기 때문에 당연한 결과가 나오는걸 방지하기 위하여 주식관련 키워드 제외
    - 총 기사 개수와 거래량 수 구하기
    
- 최종 데이터 총 개수
  
|날짜|887| 
|------|---|
|거래량|887| 
|기사개수|887| 

# 데이터 분석

## 1. 거래활동과 뉴스 정보를 단순 정규 회귀 분석 : 라쏘회귀
    - x : 기사수, y : 주식거래량 
    - 각 데이터를 StandardScaler/MinMaxScaler로 표준화하여 모델링
    - 라쏘회귀 사용 : 덜 중요한 특성을 제거 하기 위함 ()


## 3. 정리한 데이터를 기반으로 그래프 작성(시각화)
    - 기사버즈량 및 주가 비교

<img src="https://github.com/yumioh/data_analysis/assets/38059057/16b4b68f-d653-4347-a362-f5627e8b049b" width="70%" height="30%"/>

    - 일자별 기사 관심도 
<img src="https://github.com/yumioh/data_analysis/assets/38059057/d80a6ea9-edc9-4f35-bea4-e5166a49f855" width="70%" height="30%"/>

    - 카테고리별 기사량
<img src="https://github.com/yumioh/data_analysis/assets/38059057/f12404b6-0e86-4a65-8dd8-381d15784676" width="70%" height="30%"/>

## 4. 워드 클라우드 만들기
    - 모든 기사 워드클라우드 
<img src="https://github.com/yumioh/data_analysis/assets/38059057/bee57bcf-e516-42c3-bbb7-7daf00504dec" width="70%" height="50%"/>

    - 버즈량이 가장 많은 일자 워드 클라우드 : 8월 16일과 8일 
<div class="image-container">
    <img src="https://github.com/yumioh/data_analysis/assets/38059057/b5280d9d-82f0-4a3a-bc75-c02f639f359b" width="48%" height="50%" margin="5px"/>
    <img src="https://github.com/yumioh/data_analysis/assets/38059057/a6112af7-8ebf-443b-b024-f297509a080f" width="48%" height="50%"/>
</div>
    

## 5. 결론
    - 기사 버즈량과 주가를 비교 했을때 크게 주가에 크게 영향이 없었고, 삼성전자가 주제라 카테고리에서 경제 부분에 많이 나타나는 것으로 보입니다
      8월 16일과 8일이 가장 버즈량이 많은 날로 워드 클라우드로 분석해서 봤을때 지난헤 8월에 태풍 카눈과 잼버린 이슈로 인해 
      두 단어와 관련된 키워드가 대부분인걸 워드 클라우드로 확인이 가능합니다
      8월달 뉴스만 수집한 데이터로 그 수가 충분하지 않아 단순히 그달에 어떤 이슈가 있었는지 정도밖에 파악이 불가합니다
      현재 데이터로 수 자체가 적어 표본의 대표성을 가질 수 없어 뉴스와 주가 상관관계가 있다는 점을 알기 어렵습니다

