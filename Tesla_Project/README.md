# 논문 구현 : LDA 모델링으로 주제를 추출하여 금융 시장 변동성 분석 <br/>

#### 사용언어 : python
#### 사용 Tools : VScode

# 논문 분석
  - 논문명 : High Quality Topic Extraction from Business News Explains Abnormal Financial Market Volatility
  - 논문 주제 : 거래 활동에 영향을 미치는 가장 관련성이 높은 뉴스를 식별하기 위해 LDA 모델링과 회귀 분석을 결합한 새로운 방법론을 도입하여 뉴스와 주식 시장의 거래 활동에 미치는 영향
  - 논문 내용 : 
    - 주제 모델링과 회귀 분석을 결합한 방법론을 소개. 이를 통해 가장 관련성이 높은 뉴스를 식별하고, 큰 거래 이벤트의 상당 부분이 뉴스 흐름을 설명 될 수 있음
    - 2003년 1월 ~ 2011년 6월까지 2,400만개 이상의 뉴스 기록과 주요 미국 주식의 S&P 500 거래 활동간의 관계를 분석 
  - 논문 내용 기반으로 연구 방법 : </br>
    `1.` 거래활동과 뉴스 정보를 회귀 분석 활용 (LASSO 회귀) </br>
    `2.` 토픽 모델링 기술을 사용하여 주제별 기능 구현 (LDA 모델링) </br>
    `3.` 해당하는 토픽의 FVE와 FPE로 통해 뉴스가 주가에 미치는 영향을 분석 </br>
  - 연구 결론 :
    - 715개 토픽이 거래 활동에 상당한 영향 미친다고 조사. 하지만 모든 주제가 의미 있는 정보를 갖지 않음 (715개 중 78개는 잘못 기록)
    - 그러나 98%의 토픽 분포가 관련 있는 주제를 담고 있고 미래 수익에 영향을 줄 수 있는 특이 사건을 추출해 내는 방법이기 때문에
      금융 시장에 영향을 주는 정보를 성공적으로 추출
      
<br>

# 테슬라 프로젝트 목표
  - 논문의 연구 방법 기반으로 '테슬라' 뉴스를 웹 크롤링을 하여 LDA 모델링과 일론 머스크의 발언에 따른 주가 스윙 분석
  - 주가에 영향을 주는 예상 키워드 : 머스크, X(트위터), 2차전지, AI

<br>

# 데이터 수집 

## 1. 테슬라 주가
    - 기간 : 2020.01.01 ~ 2023.09.30 (3년 9개월)
    - 수집대상 : 테슬라 주가 (인베스팅 사이트 통한 주가 파일 다운로드)
    - 수집항목 : 날짜, 종가, 시가, 고가, 저가, 거래량, 변동
    - stocks.csv 파일로 저장

## 2. 테슬라 뉴스
    - 기간 : 2020.01.01 ~ 2023.09.30 (3년 9개월)
    - 수집대상 : 네이버 뉴스 기준으로 이데일리, 한국경제, 전자신문 등 뉴스 데이터 수집 (웹 크롤링)
    - 수집항목 : 날짜, 타이틀, 기사본문, 카테고리 (카테고리가 여러개로 분류 될 경우 가장 앞에 있는 카테고리로 추출)
    - teslaNews_YYMM.csv파일로 저장

## 3. 테슬라 트위터
    - 기간 : 2020.01.01 ~ 2023.09.30 (3년 9개월)
    - 수집대상 : 일론 머스크의 twitter 데이터 수집 (selenium 사용)
    - 수집항목 : 아이디, 유저이름, 내용, 날짜 
    - YYYY_twit_data.csv파일로 저장
<br/>

# 데이터 전처리

## 1. 뉴스 기사 데이터 전처리 
    - 날짜 타입 변경, 공백처리, 불용어 처리, 기사 길이가 140 이하 삭제
    - NaN값을 빈 문자열로 대체, 불용어, 공백 처리
    
| 결측값 제거 후 | dataframe shape | (114308, 3) |
|------|---|---|
| <b>결측값 제거 전 </b> | <b> dataframe shape</b> | <b>(114208, 3)</b> |

## 2. 주식 데이터 전처리 
    - 날짜 타입 변경, 거래량 M을 제외한 숫자로만 표기 처리
    - 날짜와 거래량만 추출
    - 주식 데이터와 열 이름 통일, 기사 데이터 날짜별 기사 수 추출

## 3. 주식과 기사 데이터 병합
    - 주가 없는 날짜 제거
    - 주식에 영향을 주는 요인에 집중하기 위해 주식, 화폐 등을 표현하는 토픽을 제거 (예: 주식, 증시, 주가지수 등)
    - 총 기사 개수와 거래량 수 구하기
  
|데이터|일수| 
|------|---|
|거래량|887| 
|기사개수|887| 

# 데이터 분석

## 1. 거래활동과 뉴스 정보를 단순 정규 회귀 분석 : 라쏘회귀
    - X : 기사 수, y : 주식거래량 
    - 각 데이터를 StandardScaler/MinMaxScaler로 표준화하여 모델링
    - 라쏘회귀 사용 : 라쏘회귀를 사용한 이유는 중요한 특성만을 선택하고 나머지는 0으로 축소하여 보다 모델을 단순하게 만들어주어 해석에 용이
      1. 데이터 스케일링 : MinMaxScaler로 0,1의 값으로 데이터 스케일링
      2. K-fold 교차검증을 통해 최적의 alpha값 구함
      3. 라쏘회귀 모델로 MSE(평균 제곱 오차)값과 R-squared(결정계수)값 확인

## - 결정게수(R-squared)와 K-fold, MSE값

<img src="https://github.com/yumioh/data_analysis/assets/38059057/8af56919-59c6-4421-8e02-ba7378a02709" width="60%" height="30%"/>

## - 라쏘회귀 시각화

<img src="https://github.com/yumioh/data_analysis/assets/38059057/16f3eb89-90d1-4c18-b14b-73eb2dc1b3bd" width="60%" height="30%"/>

## 2. LDA 모델링
    - LDA는 토픽 모델링의 가장 대표적인 알고리즘으로 문서의 집합으로부터 어떤 토픽이 존재하지를 알아내기 위한 알고리즘
    - 토픽 개수 30개내로 한정 => 뉴스 기록 숫자에 따라 토픽 개수를 달리 하는 것은 결과에 큰 변화를 불려오지 않음
    - LDAㄴ로 뉴스 정보를 주제별로 특징으로 분해하여 다차원 척도법으로 각 토픽들 간의 관계 확인
    
## 2-1 LDA 모델링 실행 순서
    1. BoW(Bag of Word) : 토픽 모델링 딕셔너리 생성하여 id2word로 용어-문서 빈도 정의
    2. TfidModel 적용 : BoW표현으로만 사용하면 모든 단어가 똑같은 중요도로 취급. 단어들의 가중치를 주기 위함
    3. LDA 모델링의 적절한 토픽수 구하기 : Perplexity(혼잡도)와 Coherence(일관성)를 이용하여 적절한 토픽수 구함
       - Perplexity : 모델이 주어진 데이터를 얼마나 잘 설명하는지에 대한 측정. 값이 낮을수록 모델이 데이터 잘 적합
       - Coherence : 토픽 간의 일관성과 단어들의 일관성을 측정하여 토픽의 해석을 개선. 값이 높을 수록 의미있고 일관되게 형성
    4. LDA 모델링 결과물 pyLDAvis로 시각화 : 다차원 척도법에 의해 각 토픽들 간의 관계 확인 
                                            가까이 있는 토픽은 서로 비슷한 토픽이고 원의 크기가 클수록 문서에 지배적인 토픽을 뜻함. 
                                            막대 그래프는 단어들의 빈도수를 나타냄. 빨간색 길이가 길수록 토픽 내에서의 빈도 수를 추정

  ## - Perplexity 시각화
     - 주어진 데이터를 바탕으로 Perplexity의 결과가 Perplexity값이 마이너스로 나와 Perplexity으로 적합한 토픽 개수 결정 불가능
       

<img src="https://github.com/yumioh/data_analysis/assets/38059057/473e8232-8466-469e-8c1d-120cb2c67195" width="60%" height="30%"/>

   ## - Coherence 시각화
      - 그래서 Coherence의 결과가 토픽의 개수가 18개 일때 토픽의 의미와 일관성을 보임

<img src="https://github.com/yumioh/data_analysis/assets/38059057/152c4102-d15e-493f-bb2d-85a224b276c6" width="60%" height="30%"/>


   ## - LDA 모델링 시각화
      - Perplexity와 Coherence를 통해 두가지 측면을 종합하여 토픽의 개수를 18개로 설정
      - topic 1,2가 가장 큰 토픽들이며, 이 토픽들의 크기와 위치를 통해 중요도와 빈도가 높고 비슷한 주제를 갖고 있는 걸 볼 수 있음
  
<img src="https://github.com/yumioh/data_analysis/assets/38059057/feb9858c-0aff-4627-9de7-2e89a53e2702" width="80%" height="80%" margin="5px"/>

  ## - LDA 모델링 시각화 : topic 1
     - topic 1의 결과를 보면 배터리, 전기차, 에너지, 반도체 등 전기차 산업의 핵심 기술과 관련된 키워드 위주로 많이 나타남
     - 이런한 키워드들은 전기차 산업의 주요 동향 및 기술 발전에 대해 인사이트를 도출 할 수 있음
     
<img src="https://github.com/yumioh/data_analysis/assets/38059057/edc6e17d-9a48-4fe0-8c80-cb4c10d92a46" width="80%" height="80%" margin="5px"/>

  ## - LDA 모델링 시각화 : topic 2
     - topic 2은 테슬라와 관련된 주제와 인물들에 대한 키워드가 주로 나타남
     - 트위터, 머스크는 테슬라와 관련된 소식을 크게 이슈화하고, 회사의 방향성에 큰 영향을 미침
     - 해고는 대규모 해고로 인한 이슈, 테슬라는 자동차 산업에서 인공지능 기술을 적극적으로 활용하고 있어 중요한 역할을 하고 있다는 것을 확인
     - 결과적으로 테슬라와 관련된 다양한 주제와 인물들에 대한 관심이 높다는 것을 의미
     
<img src="https://github.com/yumioh/data_analysis/assets/38059057/604d9d0b-2575-4f5d-b9af-d80ce720f700" width="80%" height="80%" margin="5px"/>


# FVE와 FPE 구하기
  - FVE (Fraction of Volume Explained) : 뉴스량과 거래량의 상관관계를 의미함. LDA 토픽 모델링을 통해 뽑은 상위 키워드를 선정. </br> (해당 토픽의 뉴스량) / (전체 주식 거래량)를 구함. 시각화를 통해 거래량과 해당 토픽 거래량을 비교
  - FPE (Fraction of Peaks Explained) : 거래량이 특정 임계치를 넘는 날을 피크일로 정의 (논문에서 95%이상 FPE를 사용). 해당하는 피크일에 최빈 토픽 확인
  - FPE와 FVE 값을 그래프나 차트로 시각화하여 어떤 토픽이 거래량의 변동을 가장 잘 설명하는지 확인 가능

## 1. 테슬라 전체 거래량 
<img src="https://github.com/yumioh/data_analysis/assets/38059057/e4698992-3597-48e4-94fd-c5aa114c1407" width="80%" height="80%" margin="5px"/>

## 2. FVE

#### 1) 키워드 : 배터리 
        - FVE(Fraction of Variance Explained) 그래프를 기반으로 하여 배터리 키워드와 주가 간에는 큰 영향이 없다고 판단. 
          그러나 이와는 별도로 배터리와 같은 전기차 기술적인 트렌드가 테슬라와 밀접한 관련이 있으며, 
          배터리 기술 발전과 관련된 뉴스는 테슬라와의 연관성이 높다는 점을 고려할 수 있습니다.
        - FVE 그래프를 통해 주가와 배터리 키워드 간의 직접적인 상관 관계가 낮다는 것을 나타냄. 
          하지만 테슬라가 전기차 및 재생 에너지 저장 시스템을 생산하는 기업임을 감안할 때, 배터리와 관련된 기술적인 발전이나 뉴스는 여전히 테슬라의 비즈니스에 영향을 미칠 수 있음
        - 따라서 배터리와 주가 간의 직접적인 상관 관계가 높지 않더라도, 배터리와 관련된 기술적인 트렌드와 뉴스는 테슬라와의 연관성이 높다고 볼 수 있음
        
<img src="https://github.com/yumioh/data_analysis/assets/38059057/3b727821-2aa3-4377-9c09-cfcc39fed331" width="80%" height="80%" margin="5px"/>

#### 2) 키워드 : 하이브리드
        - 하이브리드는 주로 전기차 관련 내용이 많아 전기차 산업에서 밀접한 관계가 있음. FVE 그래프를 확인 했을때 하이브리드와 테슬라 주가와 관계에 
          있어서 어느정도 영향을 미칠 수 있다고 볼수 있음. 뉴스가 테슬라의 비즈니스 전략, 경쟁사와의 경쟁, 시장 동향 등에 대한 정보를 제공할 
          수 있다고 볼 수 있음
          
<img src="https://github.com/yumioh/data_analysis/assets/38059057/23f59980-2a01-4fff-8d87-335c15ab0737" width="80%" height="80%" margin="5px"/>

#### 3) 키워드 : 트위터
        - 트위터와 테슬라 주가는 크게 영향이 없어 보임. 트위터 키워드가 많이 나온 이유는 테슬라 CEO인 일론 머스크가 활발한 트위터 활동으로 
          관심을 끌기도 했고, 그로 인해 테슬라 관련 뉴스가 트위터에 빈전하게 언급되는 경우가 많음
        - 테슬라와 같은 혁신적인 기업에 대한 관심이 쇼셜 미디어에 관심이 높음. 해당 키워드가 뉴스 데이터에 두드러지게 나타날 수 있음
        - 주가에 영향이 없지만 이러한 이유들로 트위터 키워드가 많이 나왔을 수도 있음
<img src="https://github.com/yumioh/data_analysis/assets/38059057/16cdc390-55f9-4f12-86d5-51019a0ebe75" width="80%" height="80%" margin="5px"/>

#### 4) 키워드 : 로봇
        - FVE 그래프를 확인 했을때, 로봇 키워드와 주가는 상관 관계가 있어보임. 테슬라는 자율 주행 기술와 같은 기술을 개발 기업.
          로봇 기술이 테슬라의 제품과 서비스에 적용될 가능성이 높음. 
        - 자율주행 기술은 인공지능과 머신러닝과 같은 첨단 기술에 기반하고 있으며, 로봇도 이와 관련이 깊은 분야 중 하나. 
          로봇 기술에 대한 뉴스는 테슬라의 인공지능의 자율 주행 기술과의 관련성을 시사
        - 테슬라가 로봇기술을 활용하여 혁신적인 제품이나 서비스를 선보인다는 전망이 있는 경우, 시장에 긍정적으로 평가할 수 있으며
          이것이 주가에 영향을 준다고 볼 수 있음
<img src="https://github.com/yumioh/data_analysis/assets/38059057/730870d2-32f6-418a-b02e-843a07208b14" width="80%" height="80%" margin="5px"/>


## 5. 결론
    - 

## 6. 한계
    1. 뉴스 소스의 높은 품질 부족 
       - 논문에서 사용한 뉴스는 품질이 높아 신호 대 잡음비가 적게 발생. 또한, 전문 투자자를 대상으로 수집된 정보 
       - 그래서 트윗, 블로그 등 다른 표준덱스트 정보와 비교할 때 전문적인 금융정보로 뛰어난 관련성을 갖고 있음 
         => 네이버 크롤링을 통해 데이터를 수집하여 금융과 관련성이 높지 않는 데이터도 다수 포함되어 있어 
            관련성이 있는 토픽을 추출하는데 어려움
</br>

    2. 충분하지 않은 데이터
       - 논문의 데이터양은 2,400만개의 데이터로 중요한 주제를 추출하는데 데이터양이 충분
         => 현재 테슬라 프로젝트는 10만개 데이터 기준으로 토픽을 추출하여 의미 없는 토픽이 나온는 경우가 생김

